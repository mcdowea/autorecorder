// åŒé€šé“å½•éŸ³æ¨¡å—
// ä½¿ç”¨ cpal åº“è¿›è¡Œè·¨å¹³å°éŸ³é¢‘å½•åˆ¶
// å‚è€ƒ Deepgram audio-recorder å®ç°

use anyhow::{Context, Result};
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use cpal::{Device, SampleFormat, StreamConfig};
use crossbeam_channel::{bounded, Sender, Receiver};
use std::sync::Arc;
use parking_lot::Mutex;
use std::time::Duration;

pub struct DualChannelRecorder {
    sample_rate: u32,
    mic_gain: f32,
    speaker_gain: f32,
}

pub struct RecordingSession {
    pub mic_receiver: Receiver<Vec<f32>>,
    pub speaker_receiver: Receiver<Vec<f32>>,
    pub stop_signal: Arc<Mutex<bool>>,
    _mic_stream: cpal::Stream,  // ä¿æŒæµå­˜æ´»
    _speaker_stream: Option<cpal::Stream>,  // æ‰¬å£°å™¨æµ(å¯é€‰)
}

impl DualChannelRecorder {
    pub fn new(sample_rate: u32) -> Self {
        Self {
            sample_rate,
            mic_gain: 1.0,
            speaker_gain: 1.0,
        }
    }

    pub fn set_mic_gain(&mut self, gain: f32) {
        self.mic_gain = gain.clamp(0.0, 2.0);
    }

    pub fn set_speaker_gain(&mut self, gain: f32) {
        self.speaker_gain = gain.clamp(0.0, 2.0);
    }

    /// å¼€å§‹å½•éŸ³,è¿”å›å½•éŸ³ä¼šè¯
    pub fn start_recording(&self) -> Result<RecordingSession> {
        let host = cpal::default_host();
        
        // è®¾ç½®é€šé“
        let (mic_tx, mic_rx) = bounded(1000);
        let (speaker_tx, speaker_rx) = bounded(1000);
        let stop_signal = Arc::new(Mutex::new(false));

        // å¯åŠ¨éº¦å…‹é£å½•éŸ³
        let mic_stream = self.start_microphone_capture(&host, mic_tx, self.mic_gain)?;
        
        // å°è¯•å¯åŠ¨æ‰¬å£°å™¨å½•éŸ³ (Loopback)
        // æ³¨æ„: Windows ä¸Šéœ€è¦ä½¿ç”¨ WASAPI Loopback
        let speaker_stream = self.start_speaker_capture(&host, speaker_tx, self.speaker_gain).ok();

        if speaker_stream.is_none() {
            println!("Warning: Speaker capture not available on this platform");
        }

        Ok(RecordingSession {
            mic_receiver: mic_rx,
            speaker_receiver: speaker_rx,
            stop_signal,
            _mic_stream: mic_stream,
            _speaker_stream: speaker_stream,
        })
    }

    /// å¯åŠ¨éº¦å…‹é£æ•è·
    fn start_microphone_capture(
        &self,
        host: &cpal::Host,
        tx: Sender<Vec<f32>>,
        gain: f32,
    ) -> Result<cpal::Stream> {
        let device = host
            .default_input_device()
            .context("No input device available")?;

        let device_name = device.name().unwrap_or_else(|_| "Unknown".to_string());
        println!("ğŸ¤ Recording from: {}", device_name);

        let config = device
            .default_input_config()
            .context("Failed to get default input config")?;

        println!("   Config: {} channels, {} Hz, {:?}",
            config.channels(),
            config.sample_rate().0,
            config.sample_format()
        );

        let stream_config: StreamConfig = config.clone().into();

        // æ ¹æ®æ ·æœ¬æ ¼å¼æ„å»ºæµ
        let stream = match config.sample_format() {
            SampleFormat::F32 => self.build_input_stream_f32(&device, &stream_config, tx, gain)?,
            SampleFormat::I16 => self.build_input_stream_i16(&device, &stream_config, tx, gain)?,
            SampleFormat::U16 => self.build_input_stream_u16(&device, &stream_config, tx, gain)?,
            _ => return Err(anyhow::anyhow!("Unsupported sample format")),
        };

        stream.play().context("Failed to start microphone stream")?;
        Ok(stream)
    }

    /// å¯åŠ¨æ‰¬å£°å™¨æ•è· (Loopback) - Windows only
    #[cfg(target_os = "windows")]
    fn start_speaker_capture(
        &self,
        host: &cpal::Host,
        tx: Sender<Vec<f32>>,
        gain: f32,
    ) -> Result<cpal::Stream> {
        // åœ¨ Windows ä¸Š,ä½¿ç”¨ output device çš„ loopback åŠŸèƒ½
        // æ³¨æ„: cpal æœ¬èº«ä¸ç›´æ¥æ”¯æŒ loopback,éœ€è¦å¹³å°ç‰¹å®šçš„å®ç°
        // è¿™é‡Œæˆ‘ä»¬å°è¯•ä½¿ç”¨é»˜è®¤è¾“å‡ºè®¾å¤‡
        
        let device = host
            .default_output_device()
            .context("No output device available")?;

        let device_name = device.name().unwrap_or_else(|_| "Unknown".to_string());
        println!("ğŸ”Š Recording from: {} (loopback)", device_name);

        // æ³¨æ„: cpal 0.16 åœ¨ Windows ä¸Šä½¿ç”¨ WASAPI,ä½†ä¸ç›´æ¥æ”¯æŒ loopback mode
        // éœ€è¦ä½¿ç”¨ Windows API ç›´æ¥è®¿é—®æˆ–è€…ä½¿ç”¨è™šæ‹ŸéŸ³é¢‘è®¾å¤‡
        // è¿™é‡Œæˆ‘ä»¬ä¿ç•™æ¥å£,ä½†å®é™…å®ç°å¯èƒ½éœ€è¦å›é€€åˆ° Windows API
        
        Err(anyhow::anyhow!("Loopback not directly supported via cpal"))
    }

    /// åœ¨é Windows å¹³å°ä¸Š,æ‰¬å£°å™¨æ•è·ä¸å¯ç”¨
    #[cfg(not(target_os = "windows"))]
    fn start_speaker_capture(
        &self,
        _host: &cpal::Host,
        _tx: Sender<Vec<f32>>,
        _gain: f32,
    ) -> Result<cpal::Stream> {
        Err(anyhow::anyhow!("Speaker capture not available on this platform"))
    }

    /// æ„å»º f32 è¾“å…¥æµ
    fn build_input_stream_f32(
        &self,
        device: &Device,
        config: &StreamConfig,
        tx: Sender<Vec<f32>>,
        gain: f32,
    ) -> Result<cpal::Stream> {
        let err_fn = |err| eprintln!("Stream error: {}", err);

        let stream = device.build_input_stream(
            config,
            move |data: &[f32], _: &cpal::InputCallbackInfo| {
                // åº”ç”¨å¢ç›Šå¹¶å‘é€æ ·æœ¬
                let samples: Vec<f32> = data.iter().map(|&s| s * gain).collect();
                let _ = tx.try_send(samples);
            },
            err_fn,
            None,
        )?;

        Ok(stream)
    }

    /// æ„å»º i16 è¾“å…¥æµ
    fn build_input_stream_i16(
        &self,
        device: &Device,
        config: &StreamConfig,
        tx: Sender<Vec<f32>>,
        gain: f32,
    ) -> Result<cpal::Stream> {
        let err_fn = |err| eprintln!("Stream error: {}", err);

        let stream = device.build_input_stream(
            config,
            move |data: &[i16], _: &cpal::InputCallbackInfo| {
                // è½¬æ¢ i16 åˆ° f32 å¹¶åº”ç”¨å¢ç›Š
                let samples: Vec<f32> = data
                    .iter()
                    .map(|&s| (s as f32 / 32768.0) * gain)
                    .collect();
                let _ = tx.try_send(samples);
            },
            err_fn,
            None,
        )?;

        Ok(stream)
    }

    /// æ„å»º u16 è¾“å…¥æµ
    fn build_input_stream_u16(
        &self,
        device: &Device,
        config: &StreamConfig,
        tx: Sender<Vec<f32>>,
        gain: f32,
    ) -> Result<cpal::Stream> {
        let err_fn = |err| eprintln!("Stream error: {}", err);

        let stream = device.build_input_stream(
            config,
            move |data: &[u16], _: &cpal::InputCallbackInfo| {
                // è½¬æ¢ u16 åˆ° f32 (centered at 32768)
                let samples: Vec<f32> = data
                    .iter()
                    .map(|&s| ((s as f32 - 32768.0) / 32768.0) * gain)
                    .collect();
                let _ = tx.try_send(samples);
            },
            err_fn,
            None,
        )?;

        Ok(stream)
    }
}

/// éŸ³é¢‘æ··éŸ³å™¨ - æ··åˆéº¦å…‹é£å’Œæ‰¬å£°å™¨éŸ³é¢‘
pub struct AudioMixer {
    mic_buffer: Vec<f32>,
    speaker_buffer: Vec<f32>,
}

impl AudioMixer {
    pub fn new() -> Self {
        Self {
            mic_buffer: Vec::new(),
            speaker_buffer: Vec::new(),
        }
    }

    /// æ·»åŠ éº¦å…‹é£æ ·æœ¬
    pub fn add_mic_samples(&mut self, samples: Vec<f32>) {
        self.mic_buffer.extend(samples);
    }

    /// æ·»åŠ æ‰¬å£°å™¨æ ·æœ¬
    pub fn add_speaker_samples(&mut self, samples: Vec<f32>) {
        self.speaker_buffer.extend(samples);
    }

    /// æ··éŸ³å¹¶è¿”å›æ··åˆåçš„æ ·æœ¬
    pub fn mix(&mut self) -> Vec<f32> {
        let len = self.mic_buffer.len().min(self.speaker_buffer.len());
        
        if len == 0 {
            // å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ··éŸ³,è¿”å›éº¦å…‹é£æ•°æ®
            let result = self.mic_buffer.clone();
            self.mic_buffer.clear();
            return result;
        }

        // æ··åˆä¸¤ä¸ªé€šé“
        let mut mixed = Vec::with_capacity(len);
        for i in 0..len {
            let mic = self.mic_buffer[i];
            let speaker = self.speaker_buffer[i];
            // ç®€å•å¹³å‡æ··éŸ³
            mixed.push((mic + speaker) * 0.5);
        }

        // ç§»é™¤å·²æ··éŸ³çš„æ ·æœ¬
        self.mic_buffer.drain(0..len);
        self.speaker_buffer.drain(0..len);

        mixed
    }

    /// è·å–å‰©ä½™çš„éº¦å…‹é£æ ·æœ¬(å½“æ²¡æœ‰æ‰¬å£°å™¨æ•°æ®æ—¶ä½¿ç”¨)
    pub fn flush_mic(&mut self) -> Vec<f32> {
        std::mem::take(&mut self.mic_buffer)
    }
}

impl Default for AudioMixer {
    fn default() -> Self {
        Self::new()
    }
}
